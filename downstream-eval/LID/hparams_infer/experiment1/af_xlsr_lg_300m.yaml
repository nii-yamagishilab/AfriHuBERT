# Generated 2024-07-14 from:
# /data/users/jalabi/Internship_NII/speechbrain/recipes/VoxLingua107/lang_id_fleur/hparams/method1/train_hubert.yaml
# yamllint disable
################################
# Model: language identification with ECAPA
# Authors: Tanel Alum√§e, 2021
# ################################

# Basic parameters
seed: 1988
__set_seed: !apply:torch.manual_seed [!ref <seed>]
__set_seed2: !apply:torch.cuda.manual_seed [!ref <seed>]
__set_seed3: !apply:random.seed [!ref <seed>]
__set_seed4: !apply:numpy.random.seed [!ref <seed>]
output_url: /data/users/jalabi/Internship_NII/speechbrain/recipes/AfroLID_FLEURS/results

# Set to directory on a large disk if you are training on Webdataset shards hosted on the web
shard_cache_dir:

pretrained_path: /data/users/jalabi/Internship_NII/speechbrain/recipes/AfroLID_FLEURS/results/experiment1/af_xlsr_lg_300m/1988/save/CKPT+2024-07-19+04-38-08+00
label_path: /data/users/jalabi/Internship_NII/speechbrain/recipes/AfroLID_FLEURS/results/experiment1/af_xlsr_lg_300m/1988/save

wav2vec2_hub: facebook/wav2vec2-xls-r-300m
wav2vec2_folder: !ref <label_path>/wav2vec

ckpt_interval_minutes: 5


####################### Training Parameters ####################################
number_of_epochs: 5
sample_rate: 16000
sentence_len: 3 # seconds
batch_size: 32
batch_size_val: 16
lr: 0.0001
lr_wav2vec2: 0.00001
num_workers: 1

#freeze all wav2vec2
freeze_wav2vec2: false
#set to true to freeze the CONV part of the wav2vec2 model
# We see an improvement of 2% with freezing CNNs
freeze_wav2vec2_conv: false

####################### Model Parameters #######################################
encoder_dim: 1024

# Number of emotions
out_n_neurons: 25 # (anger, happiness, sadness, neutral)

train_dataloader_options:
  num_workers: 1
  batch_size: 32

val_dataloader_options:
  num_workers: 1
  batch_size: 16

# Wav2vec2 encoder
wav2vec2_url: /data/users/jalabi/Internship_NII/speechbrain/recipes/AfroLID_FLEURS/fairseq/afroxlsr
wav2vec2: !new:speechbrain.lobes.models.huggingface_transformers.wav2vec2.Wav2Vec2
  source: !ref <wav2vec2_url>
  output_norm: true
  freeze: !ref <freeze_wav2vec2>
  freeze_feature_extractor: !ref <freeze_wav2vec2_conv>
  save_path: !ref <wav2vec2_folder>

attentive: !new:speechbrain.lobes.models.ECAPA_TDNN.AttentiveStatisticsPooling
  channels: 1024
  attention_channels: 64

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: 5

classifier: !new:speechbrain.lobes.models.Xvector.Classifier
  input_shape: [null, null, 2048]
  activation: !name:torch.nn.LeakyReLU
  lin_blocks: 1
  lin_neurons: 512
  out_neurons: !ref <out_n_neurons>

modules:
  wav2vec2: !ref <wav2vec2>
  attentive: !ref <attentive>
  classifier: !ref <classifier>

model: !new:torch.nn.ModuleList
- [!ref <attentive>, !ref <classifier>]
compute_cost: !name:speechbrain.nnet.losses.nll_loss

error_stats: !name:speechbrain.utils.metric_stats.MetricStats
  metric: !name:speechbrain.nnet.losses.classification_error
    reduction: batch

opt_class: !name:torch.optim.Adam
  lr: 0.0001

wav2vec2_opt_class: !name:torch.optim.Adam
  lr: 0.00001

lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler
  initial_value: !ref <lr>
  improvement_threshold: 0.0025
  annealing_factor: 0.9
  patient: 0

lr_annealing_wav2vec2: !new:speechbrain.nnet.schedulers.NewBobScheduler
  initial_value: !ref <lr_wav2vec2>
  improvement_threshold: 0.0025
  annealing_factor: 0.9

label_encoder: !new:speechbrain.dataio.encoder.CategoricalEncoder

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
  loadables:
    wav2vec2: !ref <wav2vec2>
    model: !ref <model>
    label_encoder: !ref <label_encoder>
  paths:
    wav2vec2: !ref <pretrained_path>/wav2vec2.ckpt
    model: !ref <pretrained_path>/model.ckpt
    label_encoder: !ref <label_path>/label_encoder.txt

device: cuda
